/*
import numpy as np   
import matplotlib.pyplot as plt 
import pandas as pd   

# Importing dataset   
data_set = pd.read_csv('User.csv')   
print(data_set) 

# Extracting Independent and dependent Variable   
x = data_set.iloc[:, [2, 3]].values   
y = data_set.iloc[:, 4].values   

# Splitting the dataset into training and test set.   
from sklearn.model_selection import train_test_split   
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=0)   

# Feature Scaling   
from sklearn.preprocessing import StandardScaler 
scaler = StandardScaler()     
x_train = scaler.fit_transform(x_train)     
x_test = scaler.transform(x_test)   

# Fitting Logistic Regression to the training set   
from sklearn.linear_model import LogisticRegression 
classifier = LogisticRegression(random_state=0)   
classifier.fit(x_train, y_train)  

# Predicting the test set result   
y_pred = classifier.predict(x_test)   

# Visualizing the training set result 
from matplotlib.colors import ListedColormap 
x_set, y_set = x_train, y_train 
x1, x2 = np.meshgrid(np.arange(start=x_set[:, 0].min() - 1, stop=x_set[:, 0].max() + 1, step=0.01),   
                     np.arange(start=x_set[:, 1].min() - 1, stop=x_set[:, 1].max() + 1, step=0.01))   
plt.contourf(x1, x2, classifier.predict(np.array([x1.ravel(), x2.ravel()]).T).reshape(x1.shape),
             alpha=0.75, cmap=ListedColormap(['purple', 'green']))
plt.xlim(x1.min(), x1.max())   
plt.ylim(x2.min(), x2.max())   
for i, j in enumerate(np.unique(y_set)):
    plt.scatter(x_set[y_set == j, 0], 
                x_set[y_set == j, 1],   
                c=ListedColormap(['purple', 'green'])(i), label=j)   
plt.title('Logistic Regression (Training set)')   
plt.xlabel('Age')   
plt.ylabel('Estimated Salary')   
plt.legend()
plt.show()


*/






import numpy as np

X = np.array(([2, 9], [1, 5], [3, 6]), dtype=float)
y = np.array(([92], [86], [89]), dtype=float)

X = X / np.amax(X, axis=0)  # maximum of X array longitudinally
y = y / 100  # Sigmoid Function

def sigmoid(x):
    return 1 / (1 + np.exp(-x))

# Derivative of Sigmoid Function
def derivatives_sigmoid(x):
    return x * (1 - x)

# Variable initialization
epoch = 7000  # Setting training iterations
lr = 0.1  # Setting learning rate
inputlayer_neurons = 2  # number of features in data set
hiddenlayer_neurons = 3  # number of hidden layers neurons
output_neurons = 1  # number of neurons at output layer

# weight and bias initialization
wh = np.random.uniform(size=(inputlayer_neurons, hiddenlayer_neurons))
bh = np.random.uniform(size=(1, hiddenlayer_neurons))
wout = np.random.uniform(size=(hiddenlayer_neurons, output_neurons))
bout = np.random.uniform(size=(1, output_neurons))

# Forward Propagation
for i in range(epoch):
    # Forward Propagation
    hinp1 = np.dot(X, wh)
    hinp = hinp1 + bh
    hlayer_act = sigmoid(hinp)

    outinp1 = np.dot(hlayer_act, wout)
    outinp = outinp1 + bout
    output = sigmoid(outinp)

    # Backpropagation  
    EO = y - output
    outgrad = derivatives_sigmoid(output)
    d_output = EO * outgrad

    EH = d_output.dot(wout.T)
    hiddengrad = derivatives_sigmoid(hlayer_act)
    d_hiddenlayer = EH * hiddengrad 

    wout += hlayer_act.T.dot(d_output) * lr
    bout += np.sum(d_output, axis=0, keepdims=True) * lr
    wh += X.T.dot(d_hiddenlayer) * lr
    bh += np.sum(d_hiddenlayer, axis=0, keepdims=True) * lr

print("Input: \n" + str(X))
print("Actual Output: \n" + str(y))
print("Predicted Output: \n", output)


*/



from sklearn.cluster import KMeans 
from sklearn.mixture import GaussianMixture 
import sklearn.metrics as metrics 
import pandas as pd 
import numpy as np 
import matplotlib.pyplot as plt

# Specify column names
# names = ['Sepal_Length', 'Sepal_Width', 'Petal_Length', 'Petal_Width', 'Class']

# Read the dataset
dataset = pd.read_csv("Kmean.csv") 

# Extract features and labels
X = dataset.iloc[:, :-1]
print(X)
label = {'Iris-setosa': 0, 'Iris-versicolor': 1, 'Iris-virginica': 2}  
y = [label[c] for c in dataset.iloc[:, -1]]

# Plotting
plt.figure(figsize=(14, 7)) 
colormap = np.array(['red', 'lime', 'black']) 

# REAL PLOT 
plt.subplot(1, 3, 1) 
plt.title('Real') 
plt.scatter(X.Petal_Length, X.Petal_Width, c=colormap[y]) 

# K-PLOT 
model = KMeans(n_clusters=3, random_state=0).fit(X) 
plt.subplot(1, 3, 2) 
plt.title('KMeans') 
plt.scatter(X.Petal_Length, X.Petal_Width, c=colormap[model.labels_]) 

print('The accuracy score of K-Mean: ', metrics.accuracy_score(y, model.labels_)) 
print('The Confusion matrix of K-Mean:\n', metrics.confusion_matrix(y, model.labels_)) 

# GMM PLOT 
gmm = GaussianMixture(n_components=3, random_state=0).fit(X) 
y_cluster_gmm = gmm.predict(X) 

plt.subplot(1, 3, 3) 
plt.title('GMM Classification') 
plt.scatter(X.Petal_Length, X.Petal_Width, c=colormap[y_cluster_gmm]) 

print('The accuracy score of EM: ', metrics.accuracy_score(y, y_cluster_gmm)) 
print('The Confusion matrix of EM:\n', metrics.confusion_matrix(y,Â y_cluster_gmm))






<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Document</title>
</head>
<body>
    <center>TIME TABLE</center>
    <table border="1" align="center" cellspacing="0" style="background-color: rgb(231, 229, 239); color: red;" width="200px">
        <tr>
           <th>Day/Period</th>
           <th>I\9:30-10:20</th>
           <th>II\10:20-11:20</th>
           <th>III\11:20-12:20</th>
           <th>IV\12:20-12:50</th>
           <th>12:50-1:50</th>
           <th>V\1:50-2:50</th>
           <th>I\2:50-3:50</th>
           <th>I\3:50-4:30</th>

        </tr>
        <tr>
            <td>monday</td>
            <td>eng</td>
            <td>Math</td>
            <td>Che</td>
            <td>Bio</td>
            <td rowspan="6">LUNCH</td>
            <td colspan="2">LAB</td>
            <td>Phy</td>
           
        </tr>
        <tr>
            <td>Tuesday</td>
            <td colspan="4">LAB</td>
           
            <td>ENG</td>
            <td>Che</td>
            <td>Math</td>

        </tr>
        <tr>
            <td>Wednesday</td>
            <td>ENG</td>
            <td>Che</td>
            <td>Math</td>
            <td>Sports</td>
            <td>phy</td>
            <td colspan="2">Library</td>
        </tr>
        <tr>
            <td>Thrusday</td>
            <td>Math</td>
            <td>Che</td>
            <td>Bio</td>
            <td>Sports</td>
            <td colspan="2">LAB</td>
            <td>Physics</td>
        </tr>
        <tr>
            <td>friday</td>
            <td>Math</td>
            <td>Che</td>
            <td>Bio</td>
            <td>Sports</td>
            <td colspan="2">LAB</td>
            <td>Physics</td>
        </tr>
    </table>
</body>
</html>
